---
title: "decision_tree_jc"
author: "Jeffrey Cheng"
date: "2022-11-26"
output: pdf_document
---

```{r setup, include=FALSE}

library(knitr)
library(mice)
library(caret)
library(ggfortify)
library(dplyr)
library(tibble)
library(ggplot2)
library(ggpubr)
library(GGally)
library(tidyverse)
library(readr)
library("rstudioapi")

# set default knitr chunks
knitr::opts_chunk$set(
  echo = FALSE,  # don't print the code chunk
  warning = FALSE,  # don't print warnings
  message = FALSE,  # don't print messages
  fig.width = 6,  # set default width of figures
  fig.height = 4,  # set default height of figures
  fig.align = "center",  # always align figure in center
  fig.pos = "H",  # always plot figure at the exact location of the code chunk
  fig.keep = 'all', # keep all printed figures
  cache = FALSE)  # don't cache results

```


```{r load-data, echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, results = 'hide', fig.keep = 'all'}
data_analysisvariables = read.csv("CSpine/CSV datasets/analysisvariables.csv", header = TRUE)

data = mutate(data_analysisvariables, CSI = as.integer(ControlType == 'case'))
data = select(data, -c(CaseID, StudySubjectID))



# split data into validation and test/train sets
data_test = filter(data, SITE %in% c(7,15,16))
data_model = filter(data, !SITE %in% c(7,15,16))



```
```{r statistic-functions}
model_sensitivity <- function(TP, FN) {
  return (TP / (TP + FN))
}
model_specificity <- function(TN, FP) {
  return (TN / (TN + FP))
}

```

```{r Model-Decision-Tree-Sens-Spec}
library(tree)
library(DescTools)
data_model = filter(data, !SITE %in% c(7,15,16))
# data_model = filter(data_model, ControlType %in% c("case", "ran"))

set.seed(1)
train_index=sample(1:nrow(data_model), 0.8*nrow(data_model))

# initialize arrays for sensitivity and specificity

sens_total = c()
spec_total = c()

# iterate over weights for class importance
for (j in 0:100) {
  sens_cv = c()
  spec_cv = c()
  
  # total classification
  neg = 0
  pos = 0
  # true classification
  t_neg = 0
  t_pos = 0
  
  # iterate over SITE for cross validation
  for (i in unique(data_model$SITE)){
    
    train <-  data_model[data_model$SITE!=i,]
    test <-  data_model[data_model$SITE==i,]
    
    tree.data_model = tree(as.factor(CSI)~.-SITE, data=train, weights=train$CSI*j+1)
    tree.pred = predict(tree.data_model, test, type="class")
    
    results = with(test, table(tree.pred, CSI))
    
    
    neg = neg + results[2,1] + results[1,1]
    pos = pos + results[1,2] + results[2,2]
    t_neg = t_neg + results[1,1]
    t_pos = t_pos + results[2,2]
  
  }
  # calculate confidence interval for this weight
  sens_cv = BinomCI(t_pos, n = pos, method = "wald", conf.level = 0.95)
  spec_cv = BinomCI(t_neg, n = neg, method = "wald", conf.level = 0.95)
  
  # store confidence interval
  sens_total = c(sens_total, sens_cv)
  spec_total = c(spec_total, spec_cv)

}
# collect estimates for sens and spec only
sens_est = sens_total[c(T,F,F)]
spec_est = spec_total[c(T,F,F)]

# plot performance
plot(spec_est, sens_est, type = "b", pch = 19, 
     col = "red", xlab = "specificity", ylab = "sensitivity")
# plot target lines
lines(0:0.1:1,rep(0.91 , length(0:0.1:1)))
lines(rep(0.41 , length(0:0.1:1)), 0:0.1:1)
```
```{r CI}
# confidence interval for pt closest to target (8th pt, j = 7)
sens_ci_optimal = sens_total[(3*8-2): (3*8)]
spec_ci_optimal = spec_total[(3*8-2): (3*8)]


```

```{r optimal-tree}

set.seed(1)
train_index=sample(1:nrow(data_model), 0.8*nrow(data_model))

tree.data_model = tree(as.factor(CSI)~.-SITE, data=data_model, weights=data_model$CSI*7+1, subset=train_index)
plot(tree.data_model)
text(tree.data_model, pretty=0)
tree.pred = predict(tree.data_model, data_model[-train_index,], type="class")

cv.data_model = cv.tree(tree.data_model, FUN = prune.misclass)
prune.data_model = prune.misclass(tree.data_model, k=0)
plot(prune.data_model)
text(prune.data_model, pretty=0)


```
