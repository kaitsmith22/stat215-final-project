---
title: "Modeling Section"
date: "12/5/2022"
output: html_document
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)

source("./routines.R")
```


```{r, echo=FALSE}
av <- read.csv("./CSpine/CSV datasets/analysisvariables.csv")
radiology <- read.csv("./CSpine/CSV datasets/radiologyreview.csv")
injury <- read.csv("./CSpine/CSV datasets/injuryclassification.csv")
site <- read.csv("./CSpine/CSV datasets/clinicalpresentationsite.csv")
ems <- read.csv("./CSpine/CSV datasets/clinicalpresentationfield.csv")
outside <- read.csv("./CSpine/CSV datasets/clinicalpresentationoutside.csv")
```



# Modeling

## Replicate Research Findings



## Modeling Approach

In our own modeling efforts we tried several classification methods coupled with two main approaches for features selection. Here we present two of the modeling approaches that we found amenable to interpretability and stability analysis, namely a single decision tree and linear logistic regression. For all of our modeling experiments we employed k-fold Cross Validation, with the folds determined by site (leaving one site out for each fold).
We first outline our feature selection approaches, then present out classification results.

## Feature Selection

### Bootstrapped Forward Selection

### Lasso Logistic Regression (L1 regularization)


## Classification Experiments

The first classification approach we will present is the single decision tree approach. For that we used the rpart R package [citation], and compared the cross validation results with the results from the Leonard et al paper.


```{r, echo=FALSE}
vars <- colnames(av)[5:35]
# convenience subsets (avn excludes the 3 sites, and avnn excludes NAs)

avn <- av[av$SITE != 15 & av$SITE != 16 & av$SITE != 7,]

avn_reprod <-  as.numeric(avn$AlteredMentalStatus == 1 |  avn$FocalNeuroFindings == 1 | 
                            avn$PainNeck == 1 | avn$SubInj_TorsoTrunk == 1 | avn$Predisposed == 1 |
                            avn$HighriskDiving == 1 | avn$HighriskHitByCar == 1 | 
                            avn$HighriskMVC == 1 |   avn$axialloadtop == 1 | avn$Clotheslining == 1)

avn_reprod2 <- as.numeric(avn$AlteredMentalStatus == 1 | avn$FocalNeuroFindings == 1 |  
                            avn$PainNeck == 1| avn$SubInj_TorsoTrunk == 1 | 
                            avn$HighriskDiving == 1 |avn$HighriskMVC == 1)


avnn<- avn %>% drop_na(vars)

avnn_reprod <-  as.numeric(avnn$AlteredMentalStatus == 1 |  avnn$FocalNeuroFindings == 1 | 
                            avnn$PainNeck == 1 | avnn$SubInj_TorsoTrunk == 1 | avnn$Predisposed == 1 |
                            avnn$HighriskDiving == 1 | avnn$HighriskHitByCar == 1 | 
                            avnn$HighriskMVC == 1 |   avnn$axialloadtop == 1 | avnn$Clotheslining == 1)

avnn_reprod2 <- as.numeric(avnn$AlteredMentalStatus == 1 | avnn$FocalNeuroFindings == 1 |  
                            avnn$PainNeck == 1| avnn$SubInj_TorsoTrunk == 1 | 
                            avnn$HighriskDiving == 1 |avnn$HighriskMVC == 1)


#metrics(avnn$ControlType == "case", avnn_reprod)
#metrics(avnn$ControlType == "case", avnn_reprod2)
```

### Single Decision Tree Results


```{r, echo=FALSE}
library(rpart)
avnn<- avn %>% drop_na(vars)

num_preds <- rep(0, nrow(avnn))
class_preds <- rep(0, nrow(avnn))

#num_preds <- rep(0, nrow(avn))
#class_preds <- rep(0, nrow(avn))

for (i in unique(avn$SITE)){
  train <-  avn[avn$SITE!=i,]
  test <-  avnn[avnn$SITE==i,]
  
  tree.1 <- rpart(as.numeric(ControlType == "case")~. - SITE - StudySubjectID - CaseID, 
                  data=train, 
                  #weights = (as.numeric(ControlType != "case")+1),
                  method="class",
                  parms = list(prior = c(.32,.68)))
  
  num_preds[avnn$SITE==i] <-  predict(tree.1, newdata=test)[,1]
  class_preds[avnn$SITE==i] <-  as.numeric(predict(tree.1, newdata=test, type="class"))-1
}

r <- rocs(avnn$ControlType == "case", num_preds, class_preds,  avnn_reprod, avnn_reprod2)
#r$auc
```

As we can see, classification tree prodcues an ROC curve with AUC = 0.78. The curve is strictly above the decision rule replicated from the published decision rule. Further selection of an appropriate decision threshold produces the following sensitivity/specificity metrics:

```{r, echo=FALSE}
metrics(avnn$ControlType == "case", class_preds)
```

The final list of predictors used for the decision tree is:

```{r, echo=FALSE}
tree.1$variable.importance
```

And the tree itself can be illustrated as follows:

```{r, echo=FALSE}
library(rpart.plot)
rpart.plot(tree.1)
```

One notable advantage to using decisin tree induction, is that most tree induction algorithms can handle missing data, so for the purpose of this classification model we used the whole dataset without having to remove rows with missing data, which should lend the algorithm more statistical power.

### Logistic Regression Results

Next we present the results from simple logistic regression, performed on a set of covariates chosen by the feature selection approaches we outlined above. We combined the sets of covariates selected by forward selection with the set of covariates selected by LASSO and used the intersection of the two sets for higher stability.


```{r, echo=FALSE}

avnn<- avn %>% drop_na(vars)

num_preds <- rep(0, nrow(avnn))
class_preds <- rep(0, nrow(avnn))


#  [1] "AlteredMentalStatus" "FocalNeuroFindings"  "HighriskDiving"      "HighriskHitByCar"
#  [5] "HighriskMVC"         "PainNeck2"           "Predisposed"         "SubInj_TorsoTrunk"
#  [9] "FocalNeuroFindings2" "axialloadtop"        "Torticollis2"        "LOC"
# [13] "HighriskOtherMV"     "Clotheslining"       "SubInj_Head"         "AxialLoadAnyDoc"


#  [1] "AlteredMentalStatus" "FocalNeuroFindings"  "SubInj_Head"         "SubInj_TorsoTrunk"  
#  [5] "Predisposed"         "HighriskDiving"      "HighriskHitByCar"    "HighriskMVC"        
#  [9] "HighriskOtherMV"     "AxialLoadAnyDoc"     "axialloadtop"        "FocalNeuroFindings2"
# [13] "PainNeck2"           "Torticollis2"        "subinj_Head2"        "subinj_Face2"  


for (i in unique(avnn$SITE)){
  train <-  avnn[avnn$SITE!=i,]
  test <-  avnn[avnn$SITE==i,]

  #lm.1 <- glm(as.numeric(ControlType == "case")~ .- SITE - StudySubjectID - CaseID, 
  #          data = train, family = "binomial")
  
  lm.1 <- glm(as.numeric(ControlType == "case")~ AlteredMentalStatus + FocalNeuroFindings + HighriskHitByCar +
                HighriskMVC + PainNeck2 + Predisposed + SubInj_TorsoTrunk + FocalNeuroFindings2 +
                axialloadtop + Torticollis2 + LOC + HighriskOtherMV + Clotheslining + 
                subinj_Face2 + AxialLoadAnyDoc, 
            data = train, family = "binomial")

  num_preds[avnn$SITE==i] <-  predict(lm.1, type = "response", newdata=test)
}

class_preds <- as.numeric(num_preds > 0.072)

r <- rocs(avnn$ControlType == "case", num_preds, class_preds,  avnn_reprod, avnn_reprod2)
$r$auc
```

Again, the logistic regression produced an ROC curve that was strictly dominant to the published decision rule (according to our CV) with AUC = 0.81. A choice of a suitable decision threshold produced the following sensitivity/specificity metrics:

```{r, echo=FALSE}
metrics(avnn$ControlType == "case", class_preds)
```

The list of predictors used for the logistic regression model is:

```{r, echo=FALSE}
lm.1$coefficients
```

In addition to these two approaches we have experimented with neural networks and gradient boosting (on stubs and trees). Both approaches yielded results that were not much better than the approaches we presented here, and produced models that were more difficult to interpret, so we chose to omit them from this report.


## Interpretation



